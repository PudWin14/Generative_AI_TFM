{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self,kernel_size:int,number_of_clases:int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1,32,kernel_size=kernel_size),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,64,kernel_size=kernel_size),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64,128,kernel_size=kernel_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        self.classifiyer = nn.Sequential(\n",
    "            nn.Linear(128*kernel_size*kernel_size,110),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(110,number_of_clases),\n",
    "            nn.Softmax(1)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.classifiyer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.rand((20,1,28,28)).cuda()\n",
    "# img =img[None,:].cuda()\n",
    "lbl = torch.randint(0,25,(20,1)).cuda()\n",
    "lbl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "conv_classfier = ConvNet(3,26).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = conv_classfier(img)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(logits,lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "from pandas import read_csv,concat\n",
    "# Import the Dataset from kaggle and load on a Tensor\n",
    "Nist_dataset = kagglehub.dataset_download(\"sachinpatel21/az-handwritten-alphabets-in-csv-format\")\n",
    "\n",
    "chunksize = 250\n",
    "\n",
    "# the list that contains all the dataframes\n",
    "list_of_dataframes = []\n",
    "\n",
    "for df in read_csv(Nist_dataset+\"/A_Z Handwritten Data.csv\", chunksize=chunksize):\n",
    "    # process your data frame here\n",
    "    # then add the current data frame into the list\n",
    "    list_of_dataframes.append(df)\n",
    "\n",
    "# if you want all the dataframes together, here it is\n",
    "handwritten_alphabet = concat(list_of_dataframes)\n",
    "\n",
    "\n",
    "\n",
    "# handwritten_alphabet = read_csv(Nist_dataset+\"/A_Z Handwritten Data.csv\")\n",
    "# print(handwritten_alphabet)\n",
    "handwritten_alphabet = torch.Tensor(handwritten_alphabet.values).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Dataset Class to load the Images and labels\n",
    "class image_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,images:torch.Tensor,labels:torch.Tensor):\n",
    "        if len(images[:]) != len(labels):\n",
    "            raise IndexError(\"The size must be the same\")\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        image = self.images[None,index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        if type(index) == list:\n",
    "            image = image.swapaxes(0,1)\n",
    "            # label = label.swapaxes(0,1)\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split The data on Images and Labels\n",
    "# handwritten_alphabet[:,0]\n",
    "handwritten_alphabet_classes = handwritten_alphabet[:,0].long()\n",
    "handwritten_alphabet_images = handwritten_alphabet[:,1:].reshape((-1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and Split the dataset on Train, Validation and Test Datasets\n",
    "image_dataset = image_dataset(handwritten_alphabet_images,handwritten_alphabet_classes)\n",
    "\n",
    "train,val,test = torch.utils.data.random_split(image_dataset,[0.8,0.1,0.1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handwritten_alphabet_classes[0:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[0:55624][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_prueba = torch.utils.data.DataLoader(\n",
    "    dataset=train,\n",
    "    shuffle=True,\n",
    "    batch_size=20\n",
    ")\n",
    "_,lbls = next(iter(loader_prueba))\n",
    "lbls.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
