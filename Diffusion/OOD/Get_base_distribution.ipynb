{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff2dce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from diffusers import PNDMScheduler, UNet2DModel\n",
    "# from diffusers import schedulers\n",
    "# from PIL import Image\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df19e1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images_tensor:torch.tensor, cmap = \"grey\"):\n",
    "    n_dims = images_tensor.dim()\n",
    "    \n",
    "    if n_dims in (2,3):\n",
    "        x_cat = images_tensor\n",
    "\n",
    "    elif n_dims == 4:\n",
    "        x_list = [img for img in images_tensor]\n",
    "        x_cat = torch.cat(x_list,dim=2)\n",
    "    \n",
    "    else:\n",
    "        raise SyntaxError(\"The dimensions of images_tensor must be between 2 and 4\")\n",
    "\n",
    "    if n_dims != 2:\n",
    "        if x_cat.shape[0] == 1:\n",
    "            plt.imshow(x_cat.movedim(0,-1),cmap);\n",
    "        else:\n",
    "            plt.imshow(x_cat.movedim(0,-1));\n",
    "    else:\n",
    "        plt.imshow(x_cat,cmap);\n",
    "def show_images_list(images_list:list[torch.Tensor], cmap = \"grey\") -> None:\n",
    "\n",
    "    images_tensor = torch.concat(images_list,dim=0)\n",
    "\n",
    "    # return images_tensor\n",
    "    # show_images(images_tensor.unsqueeze(1))\n",
    "    show_images(images_tensor.unsqueeze(1),cmap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd785cfb",
   "metadata": {},
   "source": [
    "# Cargar el Dataset de Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a56ddcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),              #To Torch Tensor\n",
    "    transforms.Pad(2),                  # Add a padding of 2 pixels\n",
    "    transforms.Normalize([0.5], [0.5])  # Normalize to (-1,1)\n",
    "])\n",
    "\n",
    "def dataset_preprocess(examples):\n",
    "    images = [preprocess(example) for example in examples[\"image\"]]\n",
    "    return {\"images\": images}\n",
    "dataset = load_dataset(\"fashion_mnist\")\n",
    "\n",
    "# train_dataset,test_dataset = torch.utils.data.random_split(dataset[\"train\"].with_transform(dataset_preprocess),(0.8,0.2))\n",
    "\n",
    "val_dataset = torch.utils.data.random_split(dataset[\"test\"].with_transform(dataset_preprocess),(1,))[0]\n",
    "\n",
    "\n",
    "# Solamente necesitamos los datos de validaciónS\n",
    "val_dataloder = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    shuffle=True,\n",
    "    batch_size=32       # Tamaño del lote de 32 imágenes. El dataset de Validación son 10.000 imágenes -> 313 lotes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02014a9",
   "metadata": {},
   "source": [
    "# Modelo\n",
    "Importamos el Modelo del fichero de pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2954131e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet2DModel(\n",
       "  (conv_in): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (time_proj): Timesteps()\n",
       "  (time_embedding): TimestepEmbedding(\n",
       "    (linear_1): Linear(in_features=32, out_features=128, bias=True)\n",
       "    (act): SiLU()\n",
       "    (linear_2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (down_blocks): ModuleList(\n",
       "    (0): DownBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (norm2): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): DownBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): AttnDownBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x Attention(\n",
       "          (group_norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (to_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (to_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (to_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (to_out): ModuleList(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "      (downsamplers): ModuleList(\n",
       "        (0): Downsample2D(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): AttnDownBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-1): 2 x Attention(\n",
       "          (group_norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (to_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (to_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (to_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (to_out): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_blocks): ModuleList(\n",
       "    (0): AttnUpBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-2): 3 x Attention(\n",
       "          (group_norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (to_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (to_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (to_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (to_out): ModuleList(\n",
       "            (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0-1): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 384, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): AttnUpBlock2D(\n",
       "      (attentions): ModuleList(\n",
       "        (0-2): 3 x Attention(\n",
       "          (group_norm): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (to_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (to_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (to_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (to_out): ModuleList(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 384, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): UpBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 192, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 96, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (norm2): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (upsamplers): ModuleList(\n",
       "        (0): Upsample2D(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): UpBlock2D(\n",
       "      (resnets): ModuleList(\n",
       "        (0): ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 96, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (norm2): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1-2): 2 x ResnetBlock2D(\n",
       "          (norm1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
       "          (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (time_emb_proj): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (norm2): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (nonlinearity): SiLU()\n",
       "          (conv_shortcut): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mid_block): UNetMidBlock2D(\n",
       "    (attentions): ModuleList(\n",
       "      (0): Attention(\n",
       "        (group_norm): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (to_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (to_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (to_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (to_out): ModuleList(\n",
       "          (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (1): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (resnets): ModuleList(\n",
       "      (0-1): 2 x ResnetBlock2D(\n",
       "        (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (time_emb_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (nonlinearity): SiLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_norm_out): GroupNorm(32, 32, eps=1e-05, affine=True)\n",
       "  (conv_act): SiLU()\n",
       "  (conv_out): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = UNet2DModel(\n",
    "    in_channels=1,  # 1 channels for grey scale\n",
    "    out_channels=1,\n",
    "    sample_size=32,  # Specify our input size\n",
    "    # The number of channels per block affects the model size\n",
    "    block_out_channels=(32, 64, 128, 256),\n",
    "    down_block_types=(\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"AttnDownBlock2D\",\n",
    "        \"AttnDownBlock2D\",\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"AttnUpBlock2D\",\n",
    "        \"AttnUpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\"\n",
    "        ),\n",
    "\n",
    ").cuda()\n",
    "\n",
    "base_model.load_state_dict(torch.load(\"Base_model_OOD_detection.pth\",weights_only=True))\n",
    "base_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72048202",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = PNDMScheduler(\n",
    "    num_train_timesteps=1000, beta_start=0.0015, beta_end=0.0195\n",
    ")\n",
    "scheduler.set_timesteps(50)    # Especificamos el nº de pasos de inferencia que usaremos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ff75a5",
   "metadata": {},
   "source": [
    "# Generación de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70fba615",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PNDM_generation_loop(input_img:torch.Tensor, input_timestep : int, model: UNet2DModel, scheduler : PNDMScheduler):\n",
    "\n",
    "    if input_img.dim() != 4:     # Control de Errores\n",
    "        raise SyntaxError(\"Error de Dimensiones. El Tensor de entrada dbe tener 4 dimensions, siendo la primera la dimensión de lote\")\n",
    "    \n",
    "    noisy_x = input_img\n",
    "\n",
    "    if input_timestep < 0 or input_timestep > 1000: # Control de Errores\n",
    "        raise SyntaxError(\"El timestep debe estar entre 0 y 1000\")\n",
    "    \n",
    "    if input_timestep == 1000:  # Si el Timestep es de 1000, se genera una imagen desde cero\n",
    "        idx = 0\n",
    "    else:                       # Si no es de 1000, se comienza desde el punto correspondiente, con los datos de la imagen deseada\n",
    "        idx = torch.where(scheduler.timesteps == input_timestep)[0][0]  # Buscamos el indice del timestep en la lista del scheduler\n",
    "\n",
    "    for t in scheduler.timesteps[idx:]:     # Iteramos sobre la lista del scheduler. Cada elemento es uno de los timesteps de la cadena\n",
    "\n",
    "        with torch.inference_mode():        # Realizamos un paso de la iteración\n",
    "            noise_pred = model(noisy_x, t,return_dict=False)[0]\n",
    "\n",
    "        scheduler_output = scheduler.step(noise_pred, t, noisy_x)   # Paso del scheduler\n",
    "\n",
    "        noisy_x = scheduler_output.prev_sample                      # Realimentamos el bucle\n",
    "    \n",
    "    return(scheduler_output.prev_sample)  # Devolvemos el resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce1b115",
   "metadata": {},
   "source": [
    "# Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c166a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.functional import mean_squared_error as MSE\n",
    "from torchmetrics.functional.image.lpips import learned_perceptual_image_patch_similarity as LPIPS\n",
    "\n",
    "# print(MSE(regeneration,img))\n",
    "# print(LPIPS(regeneration,img))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9b9517",
   "metadata": {},
   "source": [
    "# Obtención de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a98be52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1000.,  980.,  960.,  940.,  920.,  900.,  880.,  860.,  840.,  820.,\n",
      "         800.,  780.,  760.,  740.,  720.,  700.,  680.,  660.,  640.,  620.,\n",
      "         600.,  580.,  560.,  540.,  520.,  500.,  480.,  460.,  440.,  420.,\n",
      "         400.,  380.,  360.,  340.,  320.,  300.,  280.,  260.,  240.,  220.,\n",
      "         200.,  180.,  160.,  140.,  120.,  100.,   80.,   60.,   40.,   20.])\n"
     ]
    }
   ],
   "source": [
    "N = 50      # Número de Reconstrucciones\n",
    "reconstructions_timesteps = torch.arange(1000,0,-1000/N)\n",
    "print(reconstructions_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99f97dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 0/313\n",
      "====================\n",
      "\n",
      "Época 1/313\n",
      "====================\n",
      "\n",
      "Época 2/313\n",
      "====================\n",
      "\n",
      "Época 3/313\n",
      "====================\n",
      "\n",
      "Época 4/313\n",
      "====================\n",
      "\n",
      "Época 5/313\n",
      "====================\n",
      "\n",
      "Época 6/313\n",
      "====================\n",
      "\n",
      "Época 7/313\n",
      "====================\n",
      "\n",
      "Época 8/313\n",
      "====================\n",
      "\n",
      "Época 9/313\n",
      "====================\n",
      "\n",
      "Época 10/313\n",
      "====================\n",
      "\n",
      "Época 11/313\n",
      "====================\n",
      "\n",
      "Época 12/313\n",
      "====================\n",
      "\n",
      "Época 13/313\n",
      "====================\n",
      "\n",
      "Época 14/313\n",
      "====================\n",
      "\n",
      "Época 15/313\n",
      "====================\n",
      "\n",
      "Época 16/313\n",
      "====================\n",
      "\n",
      "Época 17/313\n",
      "====================\n",
      "\n",
      "Época 18/313\n",
      "====================\n",
      "\n",
      "Época 19/313\n",
      "====================\n",
      "\n",
      "Época 20/313\n",
      "====================\n",
      "\n",
      "Época 21/313\n",
      "====================\n",
      "\n",
      "Época 22/313\n",
      "====================\n",
      "\n",
      "Época 23/313\n",
      "====================\n",
      "\n",
      "Época 24/313\n",
      "====================\n",
      "\n",
      "Época 25/313\n",
      "====================\n",
      "\n",
      "Época 26/313\n",
      "====================\n",
      "\n",
      "Época 27/313\n",
      "====================\n",
      "\n",
      "Época 28/313\n",
      "====================\n",
      "\n",
      "Época 29/313\n",
      "====================\n",
      "\n",
      "Época 30/313\n",
      "====================\n",
      "\n",
      "Época 31/313\n",
      "====================\n",
      "\n",
      "Época 32/313\n",
      "====================\n",
      "\n",
      "Época 33/313\n",
      "====================\n",
      "\n",
      "Época 34/313\n",
      "====================\n",
      "\n",
      "Época 35/313\n",
      "====================\n",
      "\n",
      "Época 36/313\n",
      "====================\n",
      "\n",
      "Época 37/313\n",
      "====================\n",
      "\n",
      "Época 38/313\n",
      "====================\n",
      "\n",
      "Época 39/313\n",
      "====================\n",
      "\n",
      "Época 40/313\n",
      "====================\n",
      "\n",
      "Época 41/313\n",
      "====================\n",
      "\n",
      "Época 42/313\n",
      "====================\n",
      "\n",
      "Época 43/313\n",
      "====================\n",
      "\n",
      "Época 44/313\n",
      "====================\n",
      "\n",
      "Época 45/313\n",
      "====================\n",
      "\n",
      "Época 46/313\n",
      "====================\n",
      "\n",
      "Época 47/313\n",
      "====================\n",
      "\n",
      "Época 48/313\n",
      "====================\n",
      "\n",
      "Época 49/313\n",
      "====================\n",
      "\n",
      "Época 50/313\n",
      "====================\n",
      "\n",
      "Época 51/313\n",
      "====================\n",
      "\n",
      "Época 52/313\n",
      "====================\n",
      "\n",
      "Época 53/313\n",
      "====================\n",
      "\n",
      "Época 54/313\n",
      "====================\n",
      "\n",
      "Época 55/313\n",
      "====================\n",
      "\n",
      "Época 56/313\n",
      "====================\n",
      "\n",
      "Época 57/313\n",
      "====================\n",
      "\n",
      "Época 58/313\n",
      "====================\n",
      "\n",
      "Época 59/313\n",
      "====================\n",
      "\n",
      "Época 60/313\n",
      "====================\n",
      "\n",
      "Época 61/313\n",
      "====================\n",
      "\n",
      "Época 62/313\n",
      "====================\n",
      "\n",
      "Época 63/313\n",
      "====================\n",
      "\n",
      "Época 64/313\n",
      "====================\n",
      "\n",
      "Época 65/313\n",
      "====================\n",
      "\n",
      "Época 66/313\n",
      "====================\n",
      "\n",
      "Época 67/313\n",
      "====================\n",
      "\n",
      "Época 68/313\n",
      "====================\n",
      "\n",
      "Época 69/313\n",
      "====================\n",
      "\n",
      "Época 70/313\n",
      "====================\n",
      "\n",
      "Época 71/313\n",
      "====================\n",
      "\n",
      "Época 72/313\n",
      "====================\n",
      "\n",
      "Época 73/313\n",
      "====================\n",
      "\n",
      "Época 74/313\n",
      "====================\n",
      "\n",
      "Época 75/313\n",
      "====================\n",
      "\n",
      "Época 76/313\n",
      "====================\n",
      "\n",
      "Época 77/313\n",
      "====================\n",
      "\n",
      "Época 78/313\n",
      "====================\n",
      "\n",
      "Época 79/313\n",
      "====================\n",
      "\n",
      "Época 80/313\n",
      "====================\n",
      "\n",
      "Época 81/313\n",
      "====================\n",
      "\n",
      "Época 82/313\n",
      "====================\n",
      "\n",
      "Época 83/313\n",
      "====================\n",
      "\n",
      "Época 84/313\n",
      "====================\n",
      "\n",
      "Época 85/313\n",
      "====================\n",
      "\n",
      "Época 86/313\n",
      "====================\n",
      "\n",
      "Época 87/313\n",
      "====================\n",
      "\n",
      "Época 88/313\n",
      "====================\n",
      "\n",
      "Época 89/313\n",
      "====================\n",
      "\n",
      "Época 90/313\n",
      "====================\n",
      "\n",
      "Época 91/313\n",
      "====================\n",
      "\n",
      "Época 92/313\n",
      "====================\n",
      "\n",
      "Época 93/313\n",
      "====================\n",
      "\n",
      "Época 94/313\n",
      "====================\n",
      "\n",
      "Época 95/313\n",
      "====================\n",
      "\n",
      "Época 96/313\n",
      "====================\n",
      "\n",
      "Época 97/313\n",
      "====================\n",
      "\n",
      "Época 98/313\n",
      "====================\n",
      "\n",
      "Época 99/313\n",
      "====================\n",
      "\n",
      "Época 100/313\n",
      "====================\n",
      "\n",
      "Época 101/313\n",
      "====================\n",
      "\n",
      "Época 102/313\n",
      "====================\n",
      "\n",
      "Época 103/313\n",
      "====================\n",
      "\n",
      "Época 104/313\n",
      "====================\n",
      "\n",
      "Época 105/313\n",
      "====================\n",
      "\n",
      "Época 106/313\n",
      "====================\n",
      "\n",
      "Época 107/313\n",
      "====================\n",
      "\n",
      "Época 108/313\n",
      "====================\n",
      "\n",
      "Época 109/313\n",
      "====================\n",
      "\n",
      "Época 110/313\n",
      "====================\n",
      "\n",
      "Época 111/313\n",
      "====================\n",
      "\n",
      "Época 112/313\n",
      "====================\n",
      "\n",
      "Época 113/313\n",
      "====================\n",
      "\n",
      "Época 114/313\n",
      "====================\n",
      "\n",
      "Época 115/313\n",
      "====================\n",
      "\n",
      "Época 116/313\n",
      "====================\n",
      "\n",
      "Época 117/313\n",
      "====================\n",
      "\n",
      "Época 118/313\n",
      "====================\n",
      "\n",
      "Época 119/313\n",
      "====================\n",
      "\n",
      "Época 120/313\n",
      "====================\n",
      "\n",
      "Época 121/313\n",
      "====================\n",
      "\n",
      "Época 122/313\n",
      "====================\n",
      "\n",
      "Época 123/313\n",
      "====================\n",
      "\n",
      "Época 124/313\n",
      "====================\n",
      "\n",
      "Época 125/313\n",
      "====================\n",
      "\n",
      "Época 126/313\n",
      "====================\n",
      "\n",
      "Época 127/313\n",
      "====================\n",
      "\n",
      "Época 128/313\n",
      "====================\n",
      "\n",
      "Época 129/313\n",
      "====================\n",
      "\n",
      "Época 130/313\n",
      "====================\n",
      "\n",
      "Época 131/313\n",
      "====================\n",
      "\n",
      "Época 132/313\n",
      "====================\n",
      "\n",
      "Época 133/313\n",
      "====================\n",
      "\n",
      "Época 134/313\n",
      "====================\n",
      "\n",
      "Época 135/313\n",
      "====================\n",
      "\n",
      "Época 136/313\n",
      "====================\n",
      "\n",
      "Época 137/313\n",
      "====================\n",
      "\n",
      "Época 138/313\n",
      "====================\n",
      "\n",
      "Época 139/313\n",
      "====================\n",
      "\n",
      "Época 140/313\n",
      "====================\n",
      "\n",
      "Época 141/313\n",
      "====================\n",
      "\n",
      "Época 142/313\n",
      "====================\n",
      "\n",
      "Época 143/313\n",
      "====================\n",
      "\n",
      "Época 144/313\n",
      "====================\n",
      "\n",
      "Época 145/313\n",
      "====================\n",
      "\n",
      "Época 146/313\n",
      "====================\n",
      "\n",
      "Época 147/313\n",
      "====================\n",
      "\n",
      "Época 148/313\n",
      "====================\n",
      "\n",
      "Época 149/313\n",
      "====================\n",
      "\n",
      "Época 150/313\n",
      "====================\n",
      "\n",
      "Época 151/313\n",
      "====================\n",
      "\n",
      "Época 152/313\n",
      "====================\n",
      "\n",
      "Época 153/313\n",
      "====================\n",
      "\n",
      "Época 154/313\n",
      "====================\n",
      "\n",
      "Época 155/313\n",
      "====================\n",
      "\n",
      "Época 156/313\n",
      "====================\n",
      "\n",
      "Época 157/313\n",
      "====================\n",
      "\n",
      "Época 158/313\n",
      "====================\n",
      "\n",
      "Época 159/313\n",
      "====================\n",
      "\n",
      "Época 160/313\n",
      "====================\n",
      "\n",
      "Época 161/313\n",
      "====================\n",
      "\n",
      "Época 162/313\n",
      "====================\n",
      "\n",
      "Época 163/313\n",
      "====================\n",
      "\n",
      "Época 164/313\n",
      "====================\n",
      "\n",
      "Época 165/313\n",
      "====================\n",
      "\n",
      "Época 166/313\n",
      "====================\n",
      "\n",
      "Época 167/313\n",
      "====================\n",
      "\n",
      "Época 168/313\n",
      "====================\n",
      "\n",
      "Época 169/313\n",
      "====================\n",
      "\n",
      "Época 170/313\n",
      "====================\n",
      "\n",
      "Época 171/313\n",
      "====================\n",
      "\n",
      "Época 172/313\n",
      "====================\n",
      "\n",
      "Época 173/313\n",
      "====================\n",
      "\n",
      "Época 174/313\n",
      "====================\n",
      "\n",
      "Época 175/313\n",
      "====================\n",
      "\n",
      "Época 176/313\n",
      "====================\n",
      "\n",
      "Época 177/313\n",
      "====================\n",
      "\n",
      "Época 178/313\n",
      "====================\n",
      "\n",
      "Época 179/313\n",
      "====================\n",
      "\n",
      "Época 180/313\n",
      "====================\n",
      "\n",
      "Época 181/313\n",
      "====================\n",
      "\n",
      "Época 182/313\n",
      "====================\n",
      "\n",
      "Época 183/313\n",
      "====================\n",
      "\n",
      "Época 184/313\n",
      "====================\n",
      "\n",
      "Época 185/313\n",
      "====================\n",
      "\n",
      "Época 186/313\n",
      "====================\n",
      "\n",
      "Época 187/313\n",
      "====================\n",
      "\n",
      "Época 188/313\n",
      "====================\n",
      "\n",
      "Época 189/313\n",
      "====================\n",
      "\n",
      "Época 190/313\n",
      "====================\n",
      "\n",
      "Época 191/313\n",
      "====================\n",
      "\n",
      "Época 192/313\n",
      "====================\n",
      "\n",
      "Época 193/313\n",
      "====================\n",
      "\n",
      "Época 194/313\n",
      "====================\n",
      "\n",
      "Época 195/313\n",
      "====================\n",
      "\n",
      "Época 196/313\n",
      "====================\n",
      "\n",
      "Época 197/313\n",
      "====================\n",
      "\n",
      "Época 198/313\n",
      "====================\n",
      "\n",
      "Época 199/313\n",
      "====================\n",
      "\n",
      "Época 200/313\n",
      "====================\n",
      "\n",
      "Época 201/313\n",
      "====================\n",
      "\n",
      "Época 202/313\n",
      "====================\n",
      "\n",
      "Época 203/313\n",
      "====================\n",
      "\n",
      "Época 204/313\n",
      "====================\n",
      "\n",
      "Época 205/313\n",
      "====================\n",
      "\n",
      "Época 206/313\n",
      "====================\n",
      "\n",
      "Época 207/313\n",
      "====================\n",
      "\n",
      "Época 208/313\n",
      "====================\n",
      "\n",
      "Época 209/313\n",
      "====================\n",
      "\n",
      "Época 210/313\n",
      "====================\n",
      "\n",
      "Época 211/313\n",
      "====================\n",
      "\n",
      "Época 212/313\n",
      "====================\n",
      "\n",
      "Época 213/313\n",
      "====================\n",
      "\n",
      "Época 214/313\n",
      "====================\n",
      "\n",
      "Época 215/313\n",
      "====================\n",
      "\n",
      "Época 216/313\n",
      "====================\n",
      "\n",
      "Época 217/313\n",
      "====================\n",
      "\n",
      "Época 218/313\n",
      "====================\n",
      "\n",
      "Época 219/313\n",
      "====================\n",
      "\n",
      "Época 220/313\n",
      "====================\n",
      "\n",
      "Época 221/313\n",
      "====================\n",
      "\n",
      "Época 222/313\n",
      "====================\n",
      "\n",
      "Época 223/313\n",
      "====================\n",
      "\n",
      "Época 224/313\n",
      "====================\n",
      "\n",
      "Época 225/313\n",
      "====================\n",
      "\n",
      "Época 226/313\n",
      "====================\n",
      "\n",
      "Época 227/313\n",
      "====================\n",
      "\n",
      "Época 228/313\n",
      "====================\n",
      "\n",
      "Época 229/313\n",
      "====================\n",
      "\n",
      "Época 230/313\n",
      "====================\n",
      "\n",
      "Época 231/313\n",
      "====================\n",
      "\n",
      "Época 232/313\n",
      "====================\n",
      "\n",
      "Época 233/313\n",
      "====================\n",
      "\n",
      "Época 234/313\n",
      "====================\n",
      "\n",
      "Época 235/313\n",
      "====================\n",
      "\n",
      "Época 236/313\n",
      "====================\n",
      "\n",
      "Época 237/313\n",
      "====================\n",
      "\n",
      "Época 238/313\n",
      "====================\n",
      "\n",
      "Época 239/313\n",
      "====================\n",
      "\n",
      "Época 240/313\n",
      "====================\n",
      "\n",
      "Época 241/313\n",
      "====================\n",
      "\n",
      "Época 242/313\n",
      "====================\n",
      "\n",
      "Época 243/313\n",
      "====================\n",
      "\n",
      "Época 244/313\n",
      "====================\n",
      "\n",
      "Época 245/313\n",
      "====================\n",
      "\n",
      "Época 246/313\n",
      "====================\n",
      "\n",
      "Época 247/313\n",
      "====================\n",
      "\n",
      "Época 248/313\n",
      "====================\n",
      "\n",
      "Época 249/313\n",
      "====================\n",
      "\n",
      "Época 250/313\n",
      "====================\n",
      "\n",
      "Época 251/313\n",
      "====================\n",
      "\n",
      "Época 252/313\n",
      "====================\n",
      "\n",
      "Época 253/313\n",
      "====================\n",
      "\n",
      "Época 254/313\n",
      "====================\n",
      "\n",
      "Época 255/313\n",
      "====================\n",
      "\n",
      "Época 256/313\n",
      "====================\n",
      "\n",
      "Época 257/313\n",
      "====================\n",
      "\n",
      "Época 258/313\n",
      "====================\n",
      "\n",
      "Época 259/313\n",
      "====================\n",
      "\n",
      "Época 260/313\n",
      "====================\n",
      "\n",
      "Época 261/313\n",
      "====================\n",
      "\n",
      "Época 262/313\n",
      "====================\n",
      "\n",
      "Época 263/313\n",
      "====================\n",
      "\n",
      "Época 264/313\n",
      "====================\n",
      "\n",
      "Época 265/313\n",
      "====================\n",
      "\n",
      "Época 266/313\n",
      "====================\n",
      "\n",
      "Época 267/313\n",
      "====================\n",
      "\n",
      "Época 268/313\n",
      "====================\n",
      "\n",
      "Época 269/313\n",
      "====================\n",
      "\n",
      "Época 270/313\n",
      "====================\n",
      "\n",
      "Época 271/313\n",
      "====================\n",
      "\n",
      "Época 272/313\n",
      "====================\n",
      "\n",
      "Época 273/313\n",
      "====================\n",
      "\n",
      "Época 274/313\n",
      "====================\n",
      "\n",
      "Época 275/313\n",
      "====================\n",
      "\n",
      "Época 276/313\n",
      "====================\n",
      "\n",
      "Época 277/313\n",
      "====================\n",
      "\n",
      "Época 278/313\n",
      "====================\n",
      "\n",
      "Época 279/313\n",
      "====================\n",
      "\n",
      "Época 280/313\n",
      "====================\n",
      "\n",
      "Época 281/313\n",
      "====================\n",
      "\n",
      "Época 282/313\n",
      "====================\n",
      "\n",
      "Época 283/313\n",
      "====================\n",
      "\n",
      "Época 284/313\n",
      "====================\n",
      "\n",
      "Época 285/313\n",
      "====================\n",
      "\n",
      "Época 286/313\n",
      "====================\n",
      "\n",
      "Época 287/313\n",
      "====================\n",
      "\n",
      "Época 288/313\n",
      "====================\n",
      "\n",
      "Época 289/313\n",
      "====================\n",
      "\n",
      "Época 290/313\n",
      "====================\n",
      "\n",
      "Época 291/313\n",
      "====================\n",
      "\n",
      "Época 292/313\n",
      "====================\n",
      "\n",
      "Época 293/313\n",
      "====================\n",
      "\n",
      "Época 294/313\n",
      "====================\n",
      "\n",
      "Época 295/313\n",
      "====================\n",
      "\n",
      "Época 296/313\n",
      "====================\n",
      "\n",
      "Época 297/313\n",
      "====================\n",
      "\n",
      "Época 298/313\n",
      "====================\n",
      "\n",
      "Época 299/313\n",
      "====================\n",
      "\n",
      "Época 300/313\n",
      "====================\n",
      "\n",
      "Época 301/313\n",
      "====================\n",
      "\n",
      "Época 302/313\n",
      "====================\n",
      "\n",
      "Época 303/313\n",
      "====================\n",
      "\n",
      "Época 304/313\n",
      "====================\n",
      "\n",
      "Época 305/313\n",
      "====================\n",
      "\n",
      "Época 306/313\n",
      "====================\n",
      "\n",
      "Época 307/313\n",
      "====================\n",
      "\n",
      "Época 308/313\n",
      "====================\n",
      "\n",
      "Época 309/313\n",
      "====================\n",
      "\n",
      "Época 310/313\n",
      "====================\n",
      "\n",
      "Época 311/313\n",
      "====================\n",
      "\n",
      "Época 312/313\n",
      "====================\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (16) must match the size of tensor b (32) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(imgs)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1000\u001b[39m:\n\u001b[0;32m---> 16\u001b[0m     restoration \u001b[38;5;241m=\u001b[39m \u001b[43mPNDM_generation_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     noisy_img \u001b[38;5;241m=\u001b[39m scheduler\u001b[38;5;241m.\u001b[39madd_noise(imgs,noise,t\u001b[38;5;241m.\u001b[39mint())\n",
      "Cell \u001b[0;32mIn[6], line 21\u001b[0m, in \u001b[0;36mPNDM_generation_loop\u001b[0;34m(input_img, input_timestep, model, scheduler)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode():        \u001b[38;5;66;03m# Realizamos un paso de la iteración\u001b[39;00m\n\u001b[1;32m     19\u001b[0m         noise_pred \u001b[38;5;241m=\u001b[39m model(noisy_x, t,return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 21\u001b[0m     scheduler_output \u001b[38;5;241m=\u001b[39m \u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoise_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoisy_x\u001b[49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# Paso del scheduler\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     noisy_x \u001b[38;5;241m=\u001b[39m scheduler_output\u001b[38;5;241m.\u001b[39mprev_sample                      \u001b[38;5;66;03m# Realimentamos el bucle\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m(scheduler_output\u001b[38;5;241m.\u001b[39mprev_sample)\n",
      "File \u001b[0;32m~/Proyectos/TFM/.venv/lib/python3.11/site-packages/diffusers/schedulers/scheduling_pndm.py:257\u001b[0m, in \u001b[0;36mPNDMScheduler.step\u001b[0;34m(self, model_output, timestep, sample, return_dict)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_prk(model_output\u001b[38;5;241m=\u001b[39mmodel_output, timestep\u001b[38;5;241m=\u001b[39mtimestep, sample\u001b[38;5;241m=\u001b[39msample, return_dict\u001b[38;5;241m=\u001b[39mreturn_dict)\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_plms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimestep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Proyectos/TFM/.venv/lib/python3.11/site-packages/diffusers/schedulers/scheduling_pndm.py:380\u001b[0m, in \u001b[0;36mPNDMScheduler.step_plms\u001b[0;34m(self, model_output, timestep, sample, return_dict)\u001b[0m\n\u001b[1;32m    378\u001b[0m     model_output \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m23\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mets[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m16\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mets[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mets[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m12\u001b[39m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     model_output \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m24\u001b[39m) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241;43m55\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m59\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m37\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mets[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m9\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mets[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m])\n\u001b[1;32m    382\u001b[0m prev_sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_prev_sample(sample, timestep, prev_timestep, model_output)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcounter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (16) must match the size of tensor b (32) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "MSE_data = [[] for _ in range(N)]\n",
    "LPIPS_data = [[] for _ in range(N)]\n",
    "\n",
    "n_epochs = len(val_dataloder)\n",
    "\n",
    "for epoch,batch in enumerate(val_dataloder):\n",
    "    imgs = batch[\"images\"].cuda()\n",
    "    print(f\"Época {epoch}/{n_epochs}\")\n",
    "    print(\"====================\")\n",
    "    print()\n",
    "\n",
    "    for idx,t in enumerate(reconstructions_timesteps):      # Tiempo estimado: 4h 20min\n",
    "        noise = torch.randn_like(imgs)\n",
    "\n",
    "        if t == 1000:\n",
    "            restoration = PNDM_generation_loop(noise,t,base_model,scheduler)\n",
    "            \n",
    "        else:\n",
    "            noisy_img = scheduler.add_noise(imgs,noise,t.int())\n",
    "            restoration = PNDM_generation_loop(noisy_img,t,base_model,scheduler)\n",
    "\n",
    "        MSE_data[idx].append(MSE(restoration,imgs))\n",
    "        \n",
    "        max_rest,min_rest = restoration.max(),restoration.min()\n",
    "        n_restoration =  2* ( ((restoration-min_rest) / (max_rest-min_rest)) - 0.5)\n",
    "\n",
    "        max_imgs,min_imgs = imgs.max(),imgs.min()\n",
    "        n_imgs =  2* ( ((imgs-min_imgs) / (max_imgs-min_imgs)) - 0.5)\n",
    "\n",
    "\n",
    "        LPIPS_data[idx].append(LPIPS(n_restoration.repeat(1,3,1,1),n_imgs.repeat(1,3,1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "581cb4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv                      # Guardar datos eb fichero para analizar más adelante\n",
    "\n",
    "file_name = \"Base_data.csv\"\n",
    "\n",
    "with open(file_name,\"w\",newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "\n",
    "    for list in MSE_data:\n",
    "        writer.writerow([\"MSE_data\"] + [x.item() for x in list])\n",
    "\n",
    "    for list in LPIPS_data:\n",
    "        writer.writerow([\"LPIPS_data\"] + [x.item() for x in list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e182ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44831ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e02516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716982a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = next(iter(val_dataloder))[\"images\"].cuda()    # Elegimos un lote de imágenes\n",
    "# print(len(img)) # Batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcf3847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_images(img[0].cpu())   # Mostramos una de las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421216ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise = torch.randn_like(img)   # Generamos el Ruido\n",
    "# noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c949763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rand_timestep_idx = torch.randint(0,len(timesteps_list),(1,))               # Elegimos el timestep aleatorio de la lista del Scheduler\n",
    "# rand_timestep = timesteps_list[rand_timestep_idx]\n",
    "\n",
    "# rand_timestep_tensor = torch.ones((val_dataloder.batch_size,),dtype=int)*rand_timestep\n",
    "# rand_timestep_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae12bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noisy_img = scheduler.add_noise(img,noise,rand_timestep_tensor)         # Añadimos Ruido a las imágenes\n",
    "# show_images(noisy_img[0].cpu())     # Mostramos una imagen con ruido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a630262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regeneration = PNDM_generation_loop(noisy_img,rand_timestep,base_model,scheduler)       # Realizamos la Restauración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fb99cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_images(regeneration[10:20].cpu())  # Mostramos las imágenes restauradas\n",
    "# show_images(regeneration.cpu())  # Mostramos las imágenes restauradas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221d0c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_images(img[10:20].cpu())   # Mostramos las imágenes originales\n",
    "# show_images(img.cpu())   # Mostramos las imágenes originales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c904b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE_list = []\n",
    "# for idx in range(val_dataloder.batch_size):\n",
    "#     MSE_list.append(MSE(regeneration[idx],img[idx]).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f777a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statistics\n",
    "# statistics.mean(MSE_list)\n",
    "# MSE_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3206a8",
   "metadata": {},
   "source": [
    "Pasos a seguir para obtener las distribuciones base:\n",
    "1. Obtengo una imagen\n",
    "2. Se le añaden 50 cantidades distintas de ruido.\n",
    "3. Para cada cantidad de ruido, se realiza la reconstrucción de la imagen\n",
    "4. Se calculan las métricas: MSE y LPIPS\n",
    "\n",
    "5. Tras la obtención de los datos, calculamos su distribución: Media y desviación estándar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
